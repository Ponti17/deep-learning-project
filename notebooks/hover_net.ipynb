{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hover-Net Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# System\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Misc\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ML\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "\n",
    "# Augmentations\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import random\n",
    "\n",
    "# Custom\n",
    "sys.path.append(os.path.abspath(\"..\"))\n",
    "from hover_net.dataloader.dataset import get_dataloader\n",
    "from hover_net.tools.utils import (dump_yaml, read_yaml)\n",
    "from hover_net.datasets.puma_dataset import PumaDataset\n",
    "from hover_net.dataloader.preprocessing import cropping_center, gen_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = read_yaml('../configs/config.yaml')\n",
    "config['DATA']['IMAGE_PATH'] = '../data/01_training_dataset_tif_ROIs'\n",
    "config['DATA']['GEOJSON_PATH'] = '../data/01_training_dataset_geojson_nuclei'\n",
    "config['DATA']['PATCH_SIZE'] = 1024\n",
    "config['TRAIN']['BATCH_SIZE'] = 1\n",
    "\n",
    "val_dataloader = get_dataloader(\n",
    "    dataset_type=\"puma\",\n",
    "    image_path=config[\"DATA\"][\"IMAGE_PATH\"],\n",
    "    geojson_path=config[\"DATA\"][\"GEOJSON_PATH\"],\n",
    "    with_type=True,\n",
    "    input_shape=(\n",
    "        config[\"DATA\"][\"PATCH_SIZE\"],\n",
    "        config[\"DATA\"][\"PATCH_SIZE\"]\n",
    "    ),\n",
    "    mask_shape=(\n",
    "        config[\"DATA\"][\"PATCH_SIZE\"],\n",
    "        config[\"DATA\"][\"PATCH_SIZE\"]\n",
    "    ),\n",
    "    batch_size=config[\"TRAIN\"][\"BATCH_SIZE\"],\n",
    "    run_mode=\"test\",\n",
    "    augment=False\n",
    ")\n",
    "\n",
    "# Get a batch of validation data\n",
    "feed_dict = next(iter(val_dataloader))\n",
    "print(f\"Dataloader returns: {feed_dict.keys()}\")\n",
    "print(f\"Image shape: {feed_dict['img'].shape}\")\n",
    "print(f\"NP Map shape: {feed_dict['np_map'].shape}\")\n",
    "\n",
    "img = feed_dict[\"img\"]\n",
    "np_map = feed_dict[\"np_map\"]\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(10, 5))\n",
    "axs[0].imshow(img[0])\n",
    "axs[1].imshow(np_map[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = PumaDataset(\n",
    "    image_path=config[\"DATA\"][\"IMAGE_PATH\"],\n",
    "    geojson_path=config[\"DATA\"][\"GEOJSON_PATH\"],\n",
    "    with_type=True,\n",
    "    input_shape=(\n",
    "        config[\"DATA\"][\"PATCH_SIZE\"],\n",
    "        config[\"DATA\"][\"PATCH_SIZE\"]\n",
    "    ),\n",
    "    mask_shape=(\n",
    "        config[\"DATA\"][\"PATCH_SIZE\"],\n",
    "        config[\"DATA\"][\"PATCH_SIZE\"]\n",
    "    ),\n",
    "    run_mode=\"test\",\n",
    "    augment=False,\n",
    ")\n",
    "\n",
    "img, ann = PumaDataset.load_data(dataset, 0)\n",
    "print(f\"Image shape: {img.shape}\")\n",
    "print(f\"Annotation shape: {ann.shape}\")\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(10, 5))\n",
    "axs[0].imshow(img)\n",
    "axs[1].imshow(ann[..., 0])\n",
    "\n",
    "inst_map = ann[..., 0]\n",
    "target_dict = gen_targets(inst_map, (1024, 1024))\n",
    "print(f\"Target dict: {target_dict.keys()}\")\n",
    "print(f\"hv_map shape: {target_dict['hv_map'].shape}\")\n",
    "print(f\"np_map shape: {target_dict['np_map'].shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from hover_net.models.loss import dice_loss, mse_loss, msge_loss, xentropy_loss\n",
    "\n",
    "def valid_step(\n",
    "    batch_data,\n",
    "    model,\n",
    "    loss_opts,\n",
    "    device=\"cuda\",\n",
    "):\n",
    "    \"\"\"\n",
    "    Validate the hover-net with Neptune logging.\n",
    "    \"\"\"\n",
    "    # Put model in evaluation\n",
    "    model.eval()\n",
    "\n",
    "    loss_func_dict = {\n",
    "        \"bce\": xentropy_loss,\n",
    "        \"dice\": dice_loss,\n",
    "        \"mse\": mse_loss,\n",
    "        \"msge\": msge_loss,\n",
    "    }\n",
    "\n",
    "    result_dict = {\"EMA\": {}}\n",
    "\n",
    "    def track_value(name, value):\n",
    "        result_dict[\"EMA\"].update({name: value})\n",
    "\n",
    "    imgs = batch_data[\"img\"]\n",
    "    true_np = batch_data[\"np_map\"]\n",
    "    true_hv = batch_data[\"hv_map\"]\n",
    "\n",
    "    imgs = imgs.to(device).type(torch.float32).permute(0, 3, 1, 2).contiguous()\n",
    "\n",
    "    true_np = true_np.to(device).type(torch.int64)\n",
    "    true_hv = true_hv.to(device).type(torch.float32)\n",
    "\n",
    "    true_np_onehot = F.one_hot(true_np, num_classes=2).type(torch.float32)\n",
    "    true_dict = {\n",
    "        \"np\": true_np_onehot, \n",
    "        \"hv\": true_hv,\n",
    "        }\n",
    "\n",
    "    if model.num_types is not None:\n",
    "        true_tp = batch_data[\"tp_map\"].to(device).type(torch.int64)\n",
    "        true_tp_onehot = F.one_hot(true_tp, num_classes=model.num_types).type(torch.float32)\n",
    "        true_dict[\"tp\"] = true_tp_onehot\n",
    "\n",
    "    # --------------------------------------------------------------\n",
    "    with torch.no_grad():  # dont compute gradient\n",
    "        pred_dict = model(imgs)\n",
    "        pred_dict = OrderedDict(\n",
    "            [[k, v.permute(0, 2, 3, 1).contiguous()] for k, v in pred_dict.items()]\n",
    "        )\n",
    "        pred_dict[\"np\"] = F.softmax(pred_dict[\"np\"], dim=-1)\n",
    "        if model.num_types is not None:\n",
    "            pred_dict[\"tp\"] = F.softmax(pred_dict[\"tp\"], dim=-1)\n",
    "\n",
    "        loss = 0\n",
    "        for branch_name in pred_dict.keys():\n",
    "            for loss_name, loss_weight in loss_opts[branch_name].items():\n",
    "                loss_func = loss_func_dict[loss_name]\n",
    "                loss_args = [true_dict[branch_name], pred_dict[branch_name]]\n",
    "                if loss_name == \"msge\":\n",
    "                    loss_args.extend([true_np_onehot[..., 1], device])\n",
    "                term_loss = loss_func(*loss_args)\n",
    "                track_value(f\"loss_{branch_name}_{loss_name}\", term_loss.cpu().item())\n",
    "                loss += loss_weight * term_loss\n",
    "\n",
    "        track_value(\"overall_loss\", loss.cpu().item())\n",
    "\n",
    "    return result_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hover_net.models import HoVerNetExt\n",
    "\n",
    "loss_opts = {\n",
    "    \"np\": {\"bce\": 1, \"dice\": 1},\n",
    "    \"hv\": {\"mse\": 1, \"msge\": 1},\n",
    "    \"tp\": {\"bce\": 1, \"dice\": 1},\n",
    "}\n",
    "\n",
    "config = read_yaml('../configs/config.yaml')\n",
    "config['DATA']['IMAGE_PATH'] = '../data/01_training_dataset_tif_ROIs'\n",
    "config['DATA']['GEOJSON_PATH'] = '../data/01_training_dataset_geojson_nuclei'\n",
    "config['DATA']['PATCH_SIZE'] = 256\n",
    "config['TRAIN']['BATCH_SIZE'] = 2\n",
    "\n",
    "model = HoVerNetExt(\n",
    "    backbone_name=config[\"MODEL\"][\"BACKBONE\"],\n",
    "    pretrained_backbone=config[\"MODEL\"][\"PRETRAINED\"],\n",
    "    num_types=config[\"MODEL\"][\"NUM_TYPES\"]\n",
    ")\n",
    "model.load_state_dict(torch.load('../pretrained/latest.pth', weights_only=True))\n",
    "model.to(config[\"TRAIN\"][\"DEVICE\"])\n",
    "model.eval()\n",
    "\n",
    "val_dataloader = get_dataloader(\n",
    "    dataset_type=\"puma\",\n",
    "    image_path=config[\"DATA\"][\"IMAGE_PATH\"],\n",
    "    geojson_path=config[\"DATA\"][\"GEOJSON_PATH\"],\n",
    "    with_type=True,\n",
    "    input_shape=(\n",
    "        config[\"DATA\"][\"PATCH_SIZE\"],\n",
    "        config[\"DATA\"][\"PATCH_SIZE\"]\n",
    "    ),\n",
    "    mask_shape=(\n",
    "        config[\"DATA\"][\"PATCH_SIZE\"],\n",
    "        config[\"DATA\"][\"PATCH_SIZE\"]\n",
    "    ),\n",
    "    batch_size=config[\"TRAIN\"][\"BATCH_SIZE\"],\n",
    "    run_mode=\"test\",\n",
    "    augment=True\n",
    ")\n",
    "\n",
    "# Get a batch of validation data\n",
    "feed_dict = next(iter(val_dataloader))\n",
    "print(f\"Dataloader returns: {feed_dict.keys()}\")\n",
    "\n",
    "for i, batch_data in enumerate(val_dataloader):\n",
    "    result_dict = valid_step(batch_data, model, loss_opts=loss_opts)\n",
    "    print(f\"Batch {i} - Result dict: {result_dict}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
